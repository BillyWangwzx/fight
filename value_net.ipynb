{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import pickle\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, Conv2D, Dropout, Activation, Flatten, Reshape, Concatenate\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = []\n",
    "y = []\n",
    "for i in range(8):\n",
    "    X_t.extend(pickle.load(open('C:/Users/wangzixi/Desktop/学习/斗地主/data/stage1/x_%d.pkl'%i,'rb')))\n",
    "    y.extend(pickle.load(open('C:/Users/wangzixi/Desktop/学习/斗地主/data/stage1/y_%d.pkl'%i,'rb')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = Input((5,15))\n",
    "x = Reshape((5,15,1))(inp)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(filters=128, kernel_size=(5,3),activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(64,activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(1,activation='sigmoid')(x)\n",
    "model = Model(inputs=inp, outputs=x)\n",
    "model.compile(loss='mean_squared_error', optimizer='nadam', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 210051 samples, validate on 23339 samples\n",
      "Epoch 1/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0224 - mean_absolute_error: 0.1099 - val_loss: 0.0166 - val_mean_absolute_error: 0.0916\n",
      "Epoch 2/100\n",
      "210051/210051 [==============================] - 22s 103us/step - loss: 0.0110 - mean_absolute_error: 0.0755 - val_loss: 0.0106 - val_mean_absolute_error: 0.0752\n",
      "Epoch 3/100\n",
      "210051/210051 [==============================] - 22s 103us/step - loss: 0.0086 - mean_absolute_error: 0.0665 - val_loss: 0.0092 - val_mean_absolute_error: 0.0663\n",
      "Epoch 4/100\n",
      "210051/210051 [==============================] - 22s 103us/step - loss: 0.0076 - mean_absolute_error: 0.0619 - val_loss: 0.0074 - val_mean_absolute_error: 0.0605\n",
      "Epoch 5/100\n",
      "210051/210051 [==============================] - 22s 104us/step - loss: 0.0069 - mean_absolute_error: 0.0589 - val_loss: 0.0078 - val_mean_absolute_error: 0.0603\n",
      "Epoch 6/100\n",
      "210051/210051 [==============================] - 22s 107us/step - loss: 0.0063 - mean_absolute_error: 0.0566 - val_loss: 0.0079 - val_mean_absolute_error: 0.0658\n",
      "Epoch 7/100\n",
      "210051/210051 [==============================] - 22s 104us/step - loss: 0.0061 - mean_absolute_error: 0.0553 - val_loss: 0.0057 - val_mean_absolute_error: 0.0530\n",
      "Epoch 8/100\n",
      "210051/210051 [==============================] - 22s 106us/step - loss: 0.0057 - mean_absolute_error: 0.0536 - val_loss: 0.0057 - val_mean_absolute_error: 0.0542\n",
      "Epoch 9/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0054 - mean_absolute_error: 0.0523 - val_loss: 0.0054 - val_mean_absolute_error: 0.0516\n",
      "Epoch 10/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0052 - mean_absolute_error: 0.0515 - val_loss: 0.0061 - val_mean_absolute_error: 0.0555\n",
      "Epoch 11/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0051 - mean_absolute_error: 0.0511 - val_loss: 0.0060 - val_mean_absolute_error: 0.0538\n",
      "Epoch 12/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0050 - mean_absolute_error: 0.0504 - val_loss: 0.0070 - val_mean_absolute_error: 0.0590\n",
      "Epoch 13/100\n",
      "210051/210051 [==============================] - 22s 107us/step - loss: 0.0049 - mean_absolute_error: 0.0497 - val_loss: 0.0060 - val_mean_absolute_error: 0.0544\n",
      "Epoch 14/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0048 - mean_absolute_error: 0.0492 - val_loss: 0.0057 - val_mean_absolute_error: 0.0533\n",
      "Epoch 15/100\n",
      "210051/210051 [==============================] - 22s 105us/step - loss: 0.0047 - mean_absolute_error: 0.0486 - val_loss: 0.0066 - val_mean_absolute_error: 0.0576\n",
      "Epoch 16/100\n",
      "210051/210051 [==============================] - 22s 104us/step - loss: 0.0047 - mean_absolute_error: 0.0485 - val_loss: 0.0064 - val_mean_absolute_error: 0.0548\n",
      "Epoch 17/100\n",
      "210051/210051 [==============================] - 23s 110us/step - loss: 0.0046 - mean_absolute_error: 0.0480 - val_loss: 0.0052 - val_mean_absolute_error: 0.0511\n",
      "Epoch 18/100\n",
      "210051/210051 [==============================] - 23s 109us/step - loss: 0.0045 - mean_absolute_error: 0.0477 - val_loss: 0.0056 - val_mean_absolute_error: 0.0523\n",
      "Epoch 19/100\n",
      "210051/210051 [==============================] - 23s 112us/step - loss: 0.0044 - mean_absolute_error: 0.0472 - val_loss: 0.0061 - val_mean_absolute_error: 0.0541\n",
      "Epoch 20/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0044 - mean_absolute_error: 0.0470 - val_loss: 0.0048 - val_mean_absolute_error: 0.0495- loss: 0.0044 - mean_absolute_error: 0\n",
      "Epoch 21/100\n",
      "210051/210051 [==============================] - 30s 143us/step - loss: 0.0043 - mean_absolute_error: 0.0467 - val_loss: 0.0047 - val_mean_absolute_error: 0.0492\n",
      "Epoch 22/100\n",
      "210051/210051 [==============================] - 25s 119us/step - loss: 0.0043 - mean_absolute_error: 0.0466 - val_loss: 0.0068 - val_mean_absolute_error: 0.0554\n",
      "Epoch 23/100\n",
      "210051/210051 [==============================] - 25s 121us/step - loss: 0.0043 - mean_absolute_error: 0.0463 - val_loss: 0.0049 - val_mean_absolute_error: 0.0493\n",
      "Epoch 24/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0042 - mean_absolute_error: 0.0462 - val_loss: 0.0048 - val_mean_absolute_error: 0.0496\n",
      "Epoch 25/100\n",
      "210051/210051 [==============================] - 26s 122us/step - loss: 0.0042 - mean_absolute_error: 0.0459 - val_loss: 0.0052 - val_mean_absolute_error: 0.0507\n",
      "Epoch 26/100\n",
      "210051/210051 [==============================] - 26s 122us/step - loss: 0.0042 - mean_absolute_error: 0.0458 - val_loss: 0.0049 - val_mean_absolute_error: 0.0498\n",
      "Epoch 27/100\n",
      "210051/210051 [==============================] - 24s 116us/step - loss: 0.0041 - mean_absolute_error: 0.0456 - val_loss: 0.0050 - val_mean_absolute_error: 0.0497\n",
      "Epoch 28/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0041 - mean_absolute_error: 0.0455 - val_loss: 0.0047 - val_mean_absolute_error: 0.0486\n",
      "Epoch 29/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0040 - mean_absolute_error: 0.0453 - val_loss: 0.0057 - val_mean_absolute_error: 0.0529\n",
      "Epoch 30/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0040 - mean_absolute_error: 0.0451 - val_loss: 0.0047 - val_mean_absolute_error: 0.0488\n",
      "Epoch 31/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0040 - mean_absolute_error: 0.0450 - val_loss: 0.0057 - val_mean_absolute_error: 0.0529\n",
      "Epoch 32/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0040 - mean_absolute_error: 0.0451 - val_loss: 0.0045 - val_mean_absolute_error: 0.0476\n",
      "Epoch 33/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0039 - mean_absolute_error: 0.0446 - val_loss: 0.0060 - val_mean_absolute_error: 0.0545\n",
      "Epoch 34/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0039 - mean_absolute_error: 0.0445 - val_loss: 0.0051 - val_mean_absolute_error: 0.0504\n",
      "Epoch 35/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0039 - mean_absolute_error: 0.0445 - val_loss: 0.0058 - val_mean_absolute_error: 0.0563\n",
      "Epoch 36/100\n",
      "210051/210051 [==============================] - 24s 116us/step - loss: 0.0039 - mean_absolute_error: 0.0445 - val_loss: 0.0067 - val_mean_absolute_error: 0.0542\n",
      "Epoch 37/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0039 - mean_absolute_error: 0.0445 - val_loss: 0.0057 - val_mean_absolute_error: 0.0523\n",
      "Epoch 38/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0039 - mean_absolute_error: 0.0442 - val_loss: 0.0046 - val_mean_absolute_error: 0.0474\n",
      "Epoch 39/100\n",
      "210051/210051 [==============================] - 28s 135us/step - loss: 0.0038 - mean_absolute_error: 0.0441 - val_loss: 0.0058 - val_mean_absolute_error: 0.0537\n",
      "Epoch 40/100\n",
      "210051/210051 [==============================] - 27s 127us/step - loss: 0.0038 - mean_absolute_error: 0.0440 - val_loss: 0.0044 - val_mean_absolute_error: 0.0475\n",
      "Epoch 41/100\n",
      "210051/210051 [==============================] - 27s 129us/step - loss: 0.0038 - mean_absolute_error: 0.0439 - val_loss: 0.0058 - val_mean_absolute_error: 0.0540\n",
      "Epoch 42/100\n",
      "210051/210051 [==============================] - 25s 120us/step - loss: 0.0038 - mean_absolute_error: 0.0437 - val_loss: 0.0046 - val_mean_absolute_error: 0.0491\n",
      "Epoch 43/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0038 - mean_absolute_error: 0.0438 - val_loss: 0.0044 - val_mean_absolute_error: 0.0468\n",
      "Epoch 44/100\n",
      "210051/210051 [==============================] - 26s 123us/step - loss: 0.0037 - mean_absolute_error: 0.0436 - val_loss: 0.0048 - val_mean_absolute_error: 0.0488\n",
      "Epoch 45/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0037 - mean_absolute_error: 0.0437 - val_loss: 0.0053 - val_mean_absolute_error: 0.0517\n",
      "Epoch 46/100\n",
      "210051/210051 [==============================] - 27s 130us/step - loss: 0.0038 - mean_absolute_error: 0.0435 - val_loss: 0.0045 - val_mean_absolute_error: 0.0474\n",
      "Epoch 47/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0037 - mean_absolute_error: 0.0435 - val_loss: 0.0049 - val_mean_absolute_error: 0.0499\n",
      "Epoch 48/100\n",
      "210051/210051 [==============================] - 28s 131us/step - loss: 0.0038 - mean_absolute_error: 0.0437 - val_loss: 0.0047 - val_mean_absolute_error: 0.0493\n",
      "Epoch 49/100\n",
      "210051/210051 [==============================] - 28s 131us/step - loss: 0.0037 - mean_absolute_error: 0.0434 - val_loss: 0.0061 - val_mean_absolute_error: 0.0556\n",
      "Epoch 50/100\n",
      "210051/210051 [==============================] - 25s 120us/step - loss: 0.0037 - mean_absolute_error: 0.0436 - val_loss: 0.0045 - val_mean_absolute_error: 0.0476\n",
      "Epoch 51/100\n",
      "210051/210051 [==============================] - 23s 112us/step - loss: 0.0037 - mean_absolute_error: 0.0431 - val_loss: 0.0045 - val_mean_absolute_error: 0.0481\n",
      "Epoch 52/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0037 - mean_absolute_error: 0.0433 - val_loss: 0.0048 - val_mean_absolute_error: 0.0498\n",
      "Epoch 53/100\n",
      "210051/210051 [==============================] - 23s 109us/step - loss: 0.0037 - mean_absolute_error: 0.0433 - val_loss: 0.0046 - val_mean_absolute_error: 0.0482\n",
      "Epoch 54/100\n",
      "210051/210051 [==============================] - 23s 111us/step - loss: 0.0037 - mean_absolute_error: 0.0430 - val_loss: 0.0046 - val_mean_absolute_error: 0.0480\n",
      "Epoch 55/100\n",
      "210051/210051 [==============================] - 23s 112us/step - loss: 0.0037 - mean_absolute_error: 0.0431 - val_loss: 0.0043 - val_mean_absolute_error: 0.0467\n",
      "Epoch 56/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0036 - mean_absolute_error: 0.0431 - val_loss: 0.0049 - val_mean_absolute_error: 0.0504\n",
      "Epoch 57/100\n",
      "210051/210051 [==============================] - 24s 112us/step - loss: 0.0036 - mean_absolute_error: 0.0429 - val_loss: 0.0045 - val_mean_absolute_error: 0.0473\n",
      "Epoch 58/100\n",
      "210051/210051 [==============================] - 23s 111us/step - loss: 0.0036 - mean_absolute_error: 0.0429 - val_loss: 0.0044 - val_mean_absolute_error: 0.0470\n",
      "Epoch 59/100\n",
      "210051/210051 [==============================] - 24s 112us/step - loss: 0.0036 - mean_absolute_error: 0.0428 - val_loss: 0.0043 - val_mean_absolute_error: 0.0465\n",
      "Epoch 60/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0036 - mean_absolute_error: 0.0428 - val_loss: 0.0045 - val_mean_absolute_error: 0.0475\n",
      "Epoch 61/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0036 - mean_absolute_error: 0.0429 - val_loss: 0.0045 - val_mean_absolute_error: 0.0478\n",
      "Epoch 62/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0036 - mean_absolute_error: 0.0428 - val_loss: 0.0047 - val_mean_absolute_error: 0.0480\n",
      "Epoch 63/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0036 - mean_absolute_error: 0.0427 - val_loss: 0.0044 - val_mean_absolute_error: 0.0474\n",
      "Epoch 64/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0036 - mean_absolute_error: 0.0427 - val_loss: 0.0045 - val_mean_absolute_error: 0.0476\n",
      "Epoch 65/100\n",
      "210051/210051 [==============================] - 23s 112us/step - loss: 0.0036 - mean_absolute_error: 0.0425 - val_loss: 0.0043 - val_mean_absolute_error: 0.0462\n",
      "Epoch 66/100\n",
      "210051/210051 [==============================] - 24s 112us/step - loss: 0.0036 - mean_absolute_error: 0.0426 - val_loss: 0.0044 - val_mean_absolute_error: 0.0475\n",
      "Epoch 67/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0036 - mean_absolute_error: 0.0425 - val_loss: 0.0043 - val_mean_absolute_error: 0.0466\n",
      "Epoch 68/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0035 - mean_absolute_error: 0.0425 - val_loss: 0.0044 - val_mean_absolute_error: 0.0474\n",
      "Epoch 69/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0035 - mean_absolute_error: 0.0424 - val_loss: 0.0050 - val_mean_absolute_error: 0.0505\n",
      "Epoch 70/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0036 - mean_absolute_error: 0.0425 - val_loss: 0.0052 - val_mean_absolute_error: 0.0501\n",
      "Epoch 71/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0035 - mean_absolute_error: 0.0424 - val_loss: 0.0047 - val_mean_absolute_error: 0.0489\n",
      "Epoch 72/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0036 - mean_absolute_error: 0.0424 - val_loss: 0.0043 - val_mean_absolute_error: 0.0462\n",
      "Epoch 73/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0035 - mean_absolute_error: 0.0424 - val_loss: 0.0051 - val_mean_absolute_error: 0.0502\n",
      "Epoch 74/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0035 - mean_absolute_error: 0.0422 - val_loss: 0.0045 - val_mean_absolute_error: 0.0486\n",
      "Epoch 75/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0035 - mean_absolute_error: 0.0422 - val_loss: 0.0044 - val_mean_absolute_error: 0.0472\n",
      "Epoch 76/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0035 - mean_absolute_error: 0.0423 - val_loss: 0.0045 - val_mean_absolute_error: 0.0481\n",
      "Epoch 77/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0035 - mean_absolute_error: 0.0421 - val_loss: 0.0047 - val_mean_absolute_error: 0.0492\n",
      "Epoch 78/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0035 - mean_absolute_error: 0.0422 - val_loss: 0.0045 - val_mean_absolute_error: 0.0479\n",
      "Epoch 79/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0035 - mean_absolute_error: 0.0423 - val_loss: 0.0048 - val_mean_absolute_error: 0.0492\n",
      "Epoch 80/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0035 - mean_absolute_error: 0.0422 - val_loss: 0.0047 - val_mean_absolute_error: 0.0484\n",
      "Epoch 81/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0035 - mean_absolute_error: 0.0422 - val_loss: 0.0045 - val_mean_absolute_error: 0.0476\n",
      "Epoch 82/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0035 - mean_absolute_error: 0.0421 - val_loss: 0.0046 - val_mean_absolute_error: 0.0481\n",
      "Epoch 83/100\n",
      "210051/210051 [==============================] - 25s 119us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0050 - val_mean_absolute_error: 0.0502\n",
      "Epoch 84/100\n",
      "210051/210051 [==============================] - 25s 120us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0046 - val_mean_absolute_error: 0.0485\n",
      "Epoch 85/100\n",
      "210051/210051 [==============================] - 26s 123us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0044 - val_mean_absolute_error: 0.0468\n",
      "Epoch 86/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0043 - val_mean_absolute_error: 0.0466\n",
      "Epoch 87/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0034 - mean_absolute_error: 0.0419 - val_loss: 0.0045 - val_mean_absolute_error: 0.0475\n",
      "Epoch 88/100\n",
      "210051/210051 [==============================] - 24s 116us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0045 - val_mean_absolute_error: 0.0476\n",
      "Epoch 89/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0034 - mean_absolute_error: 0.0418 - val_loss: 0.0044 - val_mean_absolute_error: 0.0469\n",
      "Epoch 90/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0034 - mean_absolute_error: 0.0417 - val_loss: 0.0046 - val_mean_absolute_error: 0.0481\n",
      "Epoch 91/100\n",
      "210051/210051 [==============================] - 25s 117us/step - loss: 0.0035 - mean_absolute_error: 0.0418 - val_loss: 0.0045 - val_mean_absolute_error: 0.0482\n",
      "Epoch 92/100\n",
      "210051/210051 [==============================] - 25s 118us/step - loss: 0.0034 - mean_absolute_error: 0.0417 - val_loss: 0.0061 - val_mean_absolute_error: 0.0540\n",
      "Epoch 93/100\n",
      "210051/210051 [==============================] - 24s 115us/step - loss: 0.0035 - mean_absolute_error: 0.0420 - val_loss: 0.0055 - val_mean_absolute_error: 0.0523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 94/100\n",
      "210051/210051 [==============================] - 23s 108us/step - loss: 0.0034 - mean_absolute_error: 0.0418 - val_loss: 0.0047 - val_mean_absolute_error: 0.0490\n",
      "Epoch 95/100\n",
      "210051/210051 [==============================] - 24s 112us/step - loss: 0.0034 - mean_absolute_error: 0.0418 - val_loss: 0.0046 - val_mean_absolute_error: 0.0484\n",
      "Epoch 96/100\n",
      "210051/210051 [==============================] - 23s 109us/step - loss: 0.0034 - mean_absolute_error: 0.0417 - val_loss: 0.0044 - val_mean_absolute_error: 0.0471\n",
      "Epoch 97/100\n",
      "210051/210051 [==============================] - 24s 116us/step - loss: 0.0034 - mean_absolute_error: 0.0416 - val_loss: 0.0044 - val_mean_absolute_error: 0.0476\n",
      "Epoch 98/100\n",
      "210051/210051 [==============================] - 24s 114us/step - loss: 0.0034 - mean_absolute_error: 0.0418 - val_loss: 0.0044 - val_mean_absolute_error: 0.0482\n",
      "Epoch 99/100\n",
      "210051/210051 [==============================] - 24s 112us/step - loss: 0.0034 - mean_absolute_error: 0.0417 - val_loss: 0.0044 - val_mean_absolute_error: 0.0477\n",
      "Epoch 100/100\n",
      "210051/210051 [==============================] - 24s 113us/step - loss: 0.0034 - mean_absolute_error: 0.0416 - val_loss: 0.0048 - val_mean_absolute_error: 0.0489\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28528532f60>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_t, y, batch_size=1024, epochs=100, validation_split=0.1) # validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(X_t,open('C:/Users/wangzixi/Desktop/学习/斗地主/data/stage1/x_all_py2.pkl','wb'))\n",
    "pickle.dump(y,open('C:/Users/wangzixi/Desktop/学习/斗地主/data/stage1/y_all.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('C:/Users/wangzixi/Desktop/doudizhu_model/value.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nJKlR/w/1YeCaN/69bwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2852f119320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pyplot.hist(y_pred,bins=100)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 1.,  0.,  1.,  2.,  1.,  1.,  0.,  2.,  1.,  2.,  0.,  0.,  0.,\n",
       "         0.,  0.]),\n",
       " array([ 2.,  1.,  2.,  0.,  2.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.]),\n",
       " array([ 0.,  2.,  0.,  1.,  0.,  1.,  2.,  0.,  1.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.]),\n",
       " array([ 1.,  1.,  1.,  1.,  1.,  2.,  2.,  2.,  2.,  2.,  4.,  4.,  4.,\n",
       "         1.,  1.]),\n",
       " array([ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.])]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_t[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50706708], dtype=float32)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5452"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_t,verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.50706708], dtype=float32)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
